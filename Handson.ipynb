{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('../data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_des() :\n",
    "    cleaned_description = get_and_clean_data()\n",
    "    cleaned_description = cleaned_description.iloc[:2]\n",
    "    \n",
    "    tokenized_description = cleaned_description.apply(lambda s : word_tokenize(s))\n",
    "    \n",
    "    sw_removed_description = tokenized_description.apply(\n",
    "        lambda s : [\n",
    "            word for word in s if word not in stopwords.words()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    sw_removed_description = sw_removed_description.apply(\n",
    "        lambda s: [\n",
    "            word for word in s if len(word) > 2\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    stemmed_description = sw_removed_description.apply(\n",
    "        lambda s: [\n",
    "            ps.stem(w) for w in s\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return stemmed_description\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  277  278  279  280  \\\n",
      "0    0    1    1    1    1    0    1    1    1    0  ...    1    1    3    1   \n",
      "1    1    0    0    0    0    1    0    0    0    1  ...    0    0    1    0   \n",
      "\n",
      "   281  282  283  284  285  286  \n",
      "0    2    1    0    5    1    0  \n",
      "1    1    0    1    1    0    1  \n",
      "\n",
      "[2 rows x 287 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stemmed_description = clean_des()\n",
    "\n",
    "cv = CountVectorizer(analyzer=lambda x:x)\n",
    "X = cv.fit_transform(stemmed_description)\n",
    "\n",
    "print(pd.DataFrame(X.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 43)\t1\n",
      "  (0, 239)\t10\n",
      "  (0, 76)\t12\n",
      "  (0, 182)\t1\n",
      "  (0, 139)\t1\n",
      "  (0, 86)\t4\n",
      "  (0, 256)\t1\n",
      "  (0, 155)\t5\n",
      "  (0, 77)\t2\n",
      "  (0, 270)\t2\n",
      "  (0, 277)\t1\n",
      "  (0, 179)\t1\n",
      "  (0, 127)\t1\n",
      "  (0, 221)\t1\n",
      "  (0, 73)\t5\n",
      "  (0, 46)\t2\n",
      "  (0, 223)\t2\n",
      "  (0, 281)\t2\n",
      "  (0, 268)\t2\n",
      "  (0, 259)\t7\n",
      "  (0, 70)\t1\n",
      "  (0, 202)\t1\n",
      "  (0, 104)\t1\n",
      "  (0, 47)\t1\n",
      "  (0, 260)\t1\n",
      "  :\t:\n",
      "  (0, 280)\t1\n",
      "  (0, 147)\t1\n",
      "  (0, 218)\t1\n",
      "  (0, 209)\t1\n",
      "  (0, 11)\t2\n",
      "  (0, 162)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 134)\t2\n",
      "  (0, 132)\t1\n",
      "  (0, 80)\t1\n",
      "  (0, 187)\t2\n",
      "  (0, 37)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 83)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 175)\t1\n",
      "  (0, 117)\t1\n",
      "  (0, 207)\t2\n",
      "  (0, 190)\t2\n",
      "  (0, 60)\t2\n",
      "  (0, 149)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 191)\t1\n",
      "  (0, 240)\t1\n",
      "  (0, 189)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X.tocsr()[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "timeit.timeit(lambda: np.matmul(X.toarray(),X.toarray().T),number=1)\n",
    "np.shape(np.matmul(X.toarray(),X.toarray().T))\n",
    "\n",
    "timeit.timeit(lambda: X*X.T,number=1)\n",
    "np.shape(X*X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016618999999877815"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: X*X.T,number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04682109999998829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: X.todok()*X.T.todok(),number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0373288000000116"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: X.tolil()*X.T.tolil(),number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004357599999991635"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: X.tocoo()*X.T.tocoo(),number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001076299999965613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: X.tocsc()*X.T.tocsc(),number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
